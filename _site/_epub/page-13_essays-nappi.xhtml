<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xml:lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="stylesheet" type="text/css" href="_assets/epub.css" />
    <title>AI-Based Provenance Research in Museums: Benefits and Risks</title>

  </head>
  <body xmlns="http://www.w3.org/1999/xhtml" id="page-essays-nappi">
            <section class="quire-page__header hero">
              <div class="hero-body">
                <h1 class="quire-page__header__title" id="ai-based-provenance-research-in-museums">
                  AI-Based Provenance Research in Museums: Benefits and Risks
                </h1>
                <div class="quire-page__header__contributor">
                  <ul class="quire-contributors-list name-title align-left">
                    <li class="quire-contributor" id="nnappi">
                      <span class="quire-contributor__name">Nichole Nappi</span>,
                      <span class="quire-contributor__affiliation">George Washington University</span>
                    </li>
                  </ul>
                </div>
              </div>
            </section>

            <section class="section quire-page__content">
              <div class="container">
                <div class="content">
                  <p>
                    During my internship at the Smithsonian Museum Support center
                    earlier this Summer, I began working on a provenance project
                    that involved organizing information, reviewing texts, and
                    searching documents to discern if a collection of objects was
                    either a loan or a donation. After eight weeks, I produced a
                    final report and a final file index to support my findings and
                    suggestions. During my Fall semester, the opportunity arose to
                    research artificial intelligence (AI) this year; I wondered
                    how this technology could support provenance research
                    workflows, speeding up the process of determining ownership
                    and clearing up issues of intellectual property. My research
                    included understanding how AI functions, recognizing the
                    associated risks of AI, and conceptulaizing how AI would
                    support provenance researchers. I initially found AI to be
                    overwhelmingly vast and intimidating; I am now excited to see
                    this tool become a reality for provenance researchers.
                  </p>
                  <p>
                    There are museums already employing AI for informative, and
                    analytical data processing. For example, as of 2020, the
                    American Museum of Natural History (AMNH) in New York used
                    IBM’s Watson Natural Language Processor (NLP) and Google Cloud
                    NLP to assess visitor surveys after they visited AMNH and
                    reviews submitted through TripAdvisor to gauge visitor
                    experiences. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Murphy and Villaespesa 2020</span><span class="quire-citation__content" hidden="">Murphy, Oonagh, and Elena Villaespesa.
                        <em>The Museums + AI Network AI: A Museum Planning
                          Toolkit.</em>
                        Goldsmiths, January 2020.</span></cite>) The Metropolitan Museum of Art used AI image recognition
                    software to assist in the metadata tagging process of their
                    artworks, making their collection more accessible. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Murphy and Villaespesa 2020</span><span class="quire-citation__content" hidden="">Murphy, Oonagh, and Elena Villaespesa.
                        <em>The Museums + AI Network AI: A Museum Planning
                          Toolkit.</em>
                        Goldsmiths, January 2020.</span></cite>) The Cooper Hewitt Smithsonian Design Museum used AI to
                    “color” sort digital artworks online for online users to
                    search artworks according to color palette. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Murphy 2022</span><span class="quire-citation__content" hidden="">Loughborough University IAS. “Dr Oonagh Murphy - AI
                        Technologies and Emerging Museum Practices.” YouTube
                        video. 30:11. March 31, 2022.
                        <a href="https://www.youtube.com/watch?v=16QxXBFo4Ps" target="_blank">https://www.youtube.com/watch?v=16QxXBFo4Ps</a>.</span></cite>) This paper proposes the use of AI for provenance research
                    due to aid in the completion of under documented objects in
                    collections.
                  </p>
                  <p>
                    This paper is meant to motivate conversations in the museum
                    community regarding AI-based provenance research. In this
                    paper, I will:
                  </p>
                  <ul>
                    <li>
                      Provide AI terminology to establish the industry vocabulary.
                    </li>
                    <li>
                      Discuss the benefits of using AI for provenance research.
                    </li>
                    <li>Define provenance as it relates to the use of AI.</li>
                    <li>
                      Discuss two of the main risks associated with AI as they
                      pertain to provenance research.
                    </li>
                    <li>Provide other considerations for discussion.</li>
                  </ul>
                  <p>
                    I will illustrate the benefits, risks, as well as the
                    practical and ethical considerations attributed to AI-based
                    provenance research. It is not the intention of this paper to
                    promote or rate specific software brands or companies.
                    However, these may be mentioned in examples from other
                    professional users and in my research findings, suggesting a
                    process for use. My technological AI experience is based on
                    research generated in the field, outside researchers using AI,
                    AI-focused news stories, and online contributors whose
                    specialty and focus is AI ethics.
                  </p>
                  <h2>Intelligence defined.</h2>
                  <p>
                    <strong>Artificial Intelligence</strong>, or
                    <strong>AI</strong>, is the simulation of human responses
                    based on a series of step-by-step mathematical instructions or
                    <strong>algorithms</strong> supplied to produce an answer or
                    to perform a function autonomously or independently. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Murphy and Villaespesa 2020</span><span class="quire-citation__content" hidden="">Murphy, Oonagh, and Elena Villaespesa.
                        <em>The Museums + AI Network AI: A Museum Planning
                          Toolkit.</em>
                        Goldsmiths, January 2020.</span></cite>) <strong>Generative AI</strong>
                    <sup class="footnote-ref"><a href="#fn1" id="fnref1" class="footnote-ref-anchor">1</a></sup>
                    is AI technology capable of creating text, images, and code
                    based on data patterns and is trained on huge quantities of
                    data so it can find patterns to create new data. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Pasick 2023</span><span class="quire-citation__content" hidden="">Pasick, Adam. “Artificial Intelligence Glossary: Neural
                        Networks and Other Terms Explained.” The New York Times,
                        March 27, 2023, sec. Technology.
                        <a href="https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html" target="_blank">https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html</a>.</span></cite>)(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Coursera 2023</span><span class="quire-citation__content" hidden="">Coursera. “Artificial Intelligence (AI) Terms: A to Z
                        Glossary,” June 15, 2023.
                        <a href="https://www.coursera.org/articles/ai-terms" target="_blank">https://www.coursera.org/articles/ai-terms</a>.</span></cite>) <strong>Large Language Models</strong> (LLMs) process large
                    amounts of data and utilize
                    <strong>natural language processing</strong>, or software
                    designed to understand and generate responses to human
                    language input.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Pasick 2023</span><span class="quire-citation__content" hidden="">Pasick, Adam. “Artificial Intelligence Glossary: Neural
                        Networks and Other Terms Explained.” The New York Times,
                        March 27, 2023, sec. Technology.
                        <a href="https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html" target="_blank">https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html</a>.</span></cite>)(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Gavrilova 2020</span><span class="quire-citation__content" hidden="">Gavrilova, Yulia. “AI vs. ML vs. DL: What’s the
                        Difference.” Blog. Serokell Software Development Company,
                        April 8, 2020.
                        <a href="https://serokell.io/blog/ai-ml-dl-difference" target="_blank">https://serokell.io/blog/ai-ml-dl-difference</a>.</span></cite>) Due to the complexity of the human language, LLMs use
                    fragments of words, or <strong>tokens</strong>, to plot
                    language as numerical vector coordinates or
                    <strong>word vectors</strong>.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Lee and Trott 2023</span><span class="quire-citation__content" hidden="">Lee, Timothy B., and Sean Trott. “A Jargon-Free
                        Explanation of How AI Large Language Models Work.” Ars
                        Technica, July 31, 2023.
                        <a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" target="_blank">https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/</a>.</span></cite>) Word vectors (a concept similar to global positioning
                    systems or GPS) provide AI the comprehensional connections and
                    pathways towards understanding human language; providing AI
                    the ability to process requests in a virtual wordscape. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Lee and Trott 2023</span><span class="quire-citation__content" hidden="">Lee, Timothy B., and Sean Trott. “A Jargon-Free
                        Explanation of How AI Large Language Models Work.” Ars
                        Technica, July 31, 2023.
                        <a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" target="_blank">https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/</a>.</span></cite>)<sup class="footnote-ref"><a href="#fn2" id="fnref2" class="footnote-ref-anchor">2</a></sup>
                    <strong>Machine learning</strong> (ML) is software that uses
                    algorithms that learn from data, observations, and actions.
                    (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Murphy and Villaespesa 2020</span><span class="quire-citation__content" hidden="">Murphy, Oonagh, and Elena Villaespesa.
                        <em>The Museums + AI Network AI: A Museum Planning
                          Toolkit.</em>
                        Goldsmiths, January 2020.</span></cite>) MLs can be either <em>descriptive</em>,
                    <em>predictive</em>, or <em>prescriptive</em>. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Brown 2021</span><span class="quire-citation__content" hidden="">Brown, Sara. “Machine Learning, Explained | MIT Sloan.”
                        Education. MIT Management Sloan School, April 21, 2021.
                        <a href="https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained" target="_blank">https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained</a>.</span></cite>)<sup class="footnote-ref"><a href="#fn3" id="fnref3" class="footnote-ref-anchor">3</a></sup>
                    As the complexity of the AI algorithm increases, the ML
                    functions and output become more complex. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Murphy and Villaespesa 2020</span><span class="quire-citation__content" hidden="">Murphy, Oonagh, and Elena Villaespesa.
                        <em>The Museums + AI Network AI: A Museum Planning
                          Toolkit.</em>
                        Goldsmiths, January 2020.</span></cite>)<sup class="footnote-ref"><a href="#fn4" id="fnref4" class="footnote-ref-anchor">4</a></sup>
                  </p>
                  <h2>Provenance, defined.</h2>
                  <p>
                    <strong>Provenance</strong>, as defined by the Getty Museum,
                    is the history of ownership as it connects objects and works
                    to its sources and origins and establishes authenticity.
                    (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Collecting &amp; Provenance Research</span><span class="quire-citation__content" hidden="">“Collecting &amp; Provenance Research (Getty Research
                        Institute).” Accessed November 30, 2023.
                        <a href="https://www.getty.edu/research/tools/provenance/" target="_blank">https://www.getty.edu/research/tools/provenance/</a>.</span></cite>) Due to early museum collection practices, there are
                    accessioned objects in museums, whose history of ownership is
                    under-documented or without a clear title.<sup class="footnote-ref"><a href="#fn5" id="fnref5" class="footnote-ref-anchor">5</a></sup>
                    As such, accessioned objects with unclear provenance cannot be
                    used to their full potential, taking up valuable space and
                    resources. Provenance research must be performed to
                    distinguish ownership history that could have implications on
                    proprietorship.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Malaro and DeAngelis 2012</span><span class="quire-citation__content" hidden="">Malaro, Marie C., and Ildiko Pogany DeAngelis.
                        <em>A Legal Primer on Managing Museum Collections.</em>
                        Third. Washington: Smithsonian Books, 2012. Kindle.</span></cite>) Considering the number of objects contained in any one
                    museum and the resources required to research to make
                    determinations, AI is an effective and efficient tool in
                    aiding provenance gaps.
                  </p>
                  <h2>AI benefits the provenance research workflow.</h2>
                  <h3><em>Efficiency</em></h3>
                  <p>
                    The answer of ownership could be as simple as locating a
                    single mis-filed loan document or as complex as sifting
                    through hours of archival materials to find 18th century
                    museum procedures for loans of unclaimed objects. Provenance
                    research requires hours of reviewing and analyzing many types
                    of archival reference materials, creating checklists,
                    establishing search criteria for online repositories and
                    archives, transcribing, and composing documents (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                        (AI) as a Resource, Methodological and Analysis Tool in
                        Qualitative Research?” The Qualitative Report, July 31,
                        2023.
                        <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>) that complete an object’s historical narrative. Aside from
                    text summarization, AI can perform as the provenance
                    researcher’s sole research assistant by:
                  </p>
                  <ul>
                    <li>
                      suggesting related terms for continued searches for
                      references.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                          (AI) as a Resource, Methodological and Analysis Tool in
                          Qualitative Research?” The Qualitative Report, July 31,
                          2023.
                          <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>)
                    </li>
                    <li>
                      providing writing prompts and feedback to aid
                      composition.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Stapleton 2023</span><span class="quire-citation__content" hidden="">Stapleton, Andy. “How To Write An A+ Essay Using AI in
                          3 Simple Steps.” YouTube video. 8:08. October 30, 2023.
                          <a href="https://www.youtube.com/watch?v=EeMm-kaYgI0" target="_blank">https://www.youtube.com/watch?v=EeMm-kaYgI0</a>.</span></cite>)
                    </li>
                    <li>
                      suggesting improvements to evidentiary findings and aiding
                      in citation. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Stapleton 2023</span><span class="quire-citation__content" hidden="">Stapleton, Andy. “How To Write An A+ Essay Using AI in
                          3 Simple Steps.” YouTube video. 8:08. October 30, 2023.
                          <a href="https://www.youtube.com/watch?v=EeMm-kaYgI0" target="_blank">https://www.youtube.com/watch?v=EeMm-kaYgI0</a>.</span></cite>)
                    </li>
                    <li>
                      creating rubrics for final reports. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Stapleton 2023</span><span class="quire-citation__content" hidden="">Stapleton, Andy. “How To Write An A+ Essay Using AI in
                          3 Simple Steps.” YouTube video. 8:08. October 30, 2023.
                          <a href="https://www.youtube.com/watch?v=EeMm-kaYgI0" target="_blank">https://www.youtube.com/watch?v=EeMm-kaYgI0</a>.</span></cite>)
                    </li>
                    <li>
                      proofing interoffice memorandums regarding provenance.
                      (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                          (AI) as a Resource, Methodological and Analysis Tool in
                          Qualitative Research?” The Qualitative Report, July 31,
                          2023.
                          <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>)
                    </li>
                  </ul>
                  <h3><em>Digitizing Early Texts</em></h3>
                  <p>
                    Considering the improvements made in neural networks and
                    natural language processing, document texts can be scanned,
                    converted, and inputted into AI applications to convert into
                    machine readable documents prior to or at the start of an
                    AI-based provenance search. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">ITS Group</span><span class="quire-citation__content" hidden="">“The Evolution of Document Scanning - How Can AI Help
                        You? | ITS Group.” Accessed November 25, 2023.
                        <a href="https://www.its-group.com/news/story/the-evolution-of-document-scanning-how-can-i-help-you" target="_blank">https://www.its-group.com/news/story/the-evolution-of-document-scanning-how-can-i-help-you</a>.</span></cite>) Prior to producing machine readable documents through AI,
                    documents were converted to readable text through the Adobe
                    Portable Document File (PDF) Professional application or
                    scanner via the Optical Content Recognition, or OCR, software
                    though the outcome is not always correct due document
                    condition or choice of sans serif typeface.<sup class="footnote-ref"><a href="#fn6" id="fnref6" class="footnote-ref-anchor">6</a></sup>
                    Training AI to transcribe printed documents is a time-saving
                    option that provides researchers with digital sources to
                    easily search and review with AI software.
                  </p>
                  <h3><em>Analysis</em></h3>
                  <p>
                    As part of the provenance process requires reading
                    biographical and subject matter texts can be processed through
                    generative AI and, when prompted, can quickly summarize and
                    organize information into digestible bullet points for quick
                    review. Christou reports AI detects “key concepts” in
                    documents, saving researchers time they would otherwise spend
                    sifting through dozens of pages of text. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                        (AI) as a Resource, Methodological and Analysis Tool in
                        Qualitative Research?” The Qualitative Report, July 31,
                        2023.
                        <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>) This aspect of AI allows provenance researchers a means to
                    prioritize evidence and acquire key information that would be
                    otherwise overlooked afters hours of reading through multiple
                    texts. AI can recommend courses of action and other concepts
                    or facts to research as part of its predictive nature. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Dikow et al. 2023.</span><span class="quire-citation__content" hidden="">Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.</span></cite>)
                  </p>
                  <p>
                    There are some aspects of the process that AI can aid in
                    assessing and determining outcomes, based on established AI
                    models supplied, for the final determination regarding an
                    object’s history of ownership.
                    <a href="https://www.aeaweb.org/articles?id=10.1257/jep.33.2.31" target="_blank">Agrawal, Gans, and Goldfarb</a>
                    state using AI as part of the workflow prevents under-testing
                    and increases the need for additional labor for downstream
                    tasks. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Agrawal, Gans, and Goldfarb 2019</span><span class="quire-citation__content" hidden="">Agrawal, Ajay, Joshua S. Gans, and Avi Goldfarb.
                        “Artificial Intelligence: The Ambiguous Labor Market
                        Impact of Automating Prediction.”
                        <em>Journal of Economic Perspectives</em> 33, no. 2 (May
                        1, 2019): 31-50.
                        <a href="https://doi.org/10.1257/jep.33.2.31" target="_blank">https://doi.org/10.1257/jep.33.2.31</a>.</span></cite>) Once a provenance researcher becomes attuned to the AI
                    workflow, transparency and accountability will be expressed
                    through published findings and accession file update.
                  </p>
                  <h2>Mitigating Bias and Inaccuracy</h2>
                  <p>
                    All technologies have risks. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">The History of Artificial Intelligence 2022</span><span class="quire-citation__content" hidden="">“The History of Artificial Intelligence (4K) | CyberWork
                        And The American Dreams | Spark.” YouTube video. 55:37.
                        July 13, 2022.
                        <a href="https://www.youtube.com/watch?v=q6U9mhKAFFA" target="_blank">https://www.youtube.com/watch?v=q6U9mhKAFFA</a>.</span></cite>) By investigating and mitigating risks now, museums can
                    prepare information and AI models which yield accurate and
                    ethical results. Two of the main risks that affect the
                    trustworthiness of AI-based provenance research is bias and
                    accuracy.
                  </p>
                  <h3><em>Bias</em></h3>
                  <p>
                    AI bias occurs when the training data retains human biases and
                    responds with biased results.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Villaespesa and French 2019</span><span class="quire-citation__content" hidden="">Villaespesa, Elena, and Ariana French. “AI, Visitor
                        Experience, and Museum Operations: A Closer Look at the
                        Possible.” 101-13, 2019.</span></cite>) Because biases exist in society, human generated data is
                    also biased. AI outputs are biased if the programmer, creating
                    the AI algorithms used to generate data, has been inserting
                    their own biases into the mix.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Biddle 2022</span><span class="quire-citation__content" hidden="">Biddle, Sam. “The Internet’s New Favorite AI Proposes
                        Torturing Iranians and Surveilling Mosques.” The
                        Intercept, December 8, 2022.
                        <a href="https://theintercept.com/2022/12/08/openai-chatgpt-ai-bias-ethics/" target="_blank">https://theintercept.com/2022/12/08/openai-chatgpt-ai-bias-ethics/</a>.</span></cite>) During the human review period or
                    <strong>AI evaluation</strong>, the reviewer can insert their
                    own biases when AI is rated. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>)
                  </p>
                  <p>
                    AI bias can be introduced at any point during an AI workflow
                    so museums should be prepared to deal with AI bias during the
                    course of AI-based research. <em>Historical biases</em> are
                    those prejudicial concepts directed at disadvantaged
                    populations.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>) For example, a historical bias that men are doctors and
                    women are nurses is an example found in earlier versions of
                    Google Translate, an application used for language
                    translation.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Brannon, Su, Vergara and Villasenor 2022</span><span class="quire-citation__content" hidden="">Brannon, Isabella, Allen Su, Caitlyn Vergara, and John
                        Villasenor. “AI &amp; Bias - When Algorithms Don’t Work,”
                        YouTube video. 7:13. September 14, 2022.
                        <a href="https://www.youtube.com/watch?v=FD-4yC95iZY" target="_blank">https://www.youtube.com/watch?v=FD-4yC95iZY</a>.</span></cite>) <em>Representation bias</em> occurs when populations are
                    inaccurately represented or the dataset of representing
                    populations is insufficient. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>) In matters of racial representation, most of the data
                    collected is significantly uneven towards one race, gender, or
                    socioeconomic level - the variation across levels is either
                    negligible or non-existent, leaving the AI little information
                    to compare and contrast.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>) <em>Measurement bias</em> occurs when selecting data with
                    specific labels and features. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>) A case using measurement bias, reported in ProPublica’s
                    article “<a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank">Machine Bias</a>,” discusses the use of flawed recidivism rate data, in
                    “predictive policing” where, despite their records and
                    offenses, people of color were subject to harsher sentences.
                    (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>)(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Angwin et al. 2023</span><span class="quire-citation__content" hidden="">Angwin, Julia, Jeff Larson, Lauren Kirchner, and Surya
                        Mattu. “Machine Bias.” ProPublica. Accessed November 14,
                        2023.
                        <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a>.</span></cite>) <strong>AI modeling</strong>, or training of data for AI,
                    can be subject to <em>evaluation bias</em> as the model is
                    improperly used for other points of reference. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Reagan 2021</span><span class="quire-citation__content" hidden="">Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.</span></cite>)
                  </p>
                  <p>
                    As decisions include object histories, the data supplied to AI
                    must be reliable and fair, and defined before deployment
                    within the AI project cycle. When AI results seem unfair, the
                    data and results should be reviewed and explained; if either
                    cannot be explained, there may be a bias involved. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">TDS Editors 2021</span><span class="quire-citation__content" hidden="">TDS Editors. “Why Eliminating Bias in AI Systems Is So
                        Hard.” Medium, October 28, 2021.
                        <a href="https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93" target="_blank">https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93</a>.</span></cite>) During the evaluation point of the AI project cycle, biases
                    will have to be mapped to determine where in the process these
                    biases are being introduced.
                  </p>
                  <p>
                    Museum staff can collectively and openly discuss the
                    definitions of bias relying on research of AI ethics
                    professionals.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Dikow et al. 2023.</span><span class="quire-citation__content" hidden="">Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.</span></cite>) For instance, Smithsonian Institution staff formed an AI
                    reading group who reviewed and discussed research-focused
                    articles prior to developing their own AI policies. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Dikow et al. 2023.</span><span class="quire-citation__content" hidden="">Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.</span></cite>) This collaborative activity provided an open arena for
                    Smithsonian staff to explore ethical issues regarding AI bias
                    in a museum environment.
                  </p>
                  <p>
                    Another way to ensure unbiased data is to become a trained
                    ethical creator of data.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">TDS Editors 2021</span><span class="quire-citation__content" hidden="">TDS Editors. “Why Eliminating Bias in AI Systems Is So
                        Hard.” Medium, October 28, 2021.
                        <a href="https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93" target="_blank">https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93</a>.</span></cite>) With the proper training, unbiased data can be created by
                    provenance researchers. For better control of data creation
                    and management, Will Keefe suggests training in
                    <a href="https://www.python.org/about/gettingstarted/" target="_blank">Python</a>, an open-source programming language incorporating and
                    maintaining standards of ethical data creation. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">TDS Editors 2021</span><span class="quire-citation__content" hidden="">TDS Editors. “Why Eliminating Bias in AI Systems Is So
                        Hard.” Medium, October 28, 2021.
                        <a href="https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93" target="_blank">https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93</a>.</span></cite>)<sup class="footnote-ref"><a href="#fn6" id="fnref6" class="footnote-ref-anchor">6</a></sup>
                  </p>
                  <p>
                    Researchers should take an “active role” in verifying AI by
                    cross-referencing results confirming AI outputs against other
                    sources, analyzing connections with other areas of research,
                    and checking for discrepancies.<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                        (AI) as a Resource, Methodological and Analysis Tool in
                        Qualitative Research?” The Qualitative Report, July 31,
                        2023.
                        <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>
                    This AI proofing checks the accuracy and trustworthiness of
                    the researcher’s findings. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                        (AI) as a Resource, Methodological and Analysis Tool in
                        Qualitative Research?” The Qualitative Report, July 31,
                        2023.
                        <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>) Christou suggests that data collection should be a varied
                    process making it easier to verify AI-based findings when
                    using the cross-referencing method.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Christou 2023</span><span class="quire-citation__content" hidden="">Christou, Prokopis. “How to Use Artificial Intelligence
                        (AI) as a Resource, Methodological and Analysis Tool in
                        Qualitative Research?” The Qualitative Report, July 31,
                        2023.
                        <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.</span></cite>) This means collecting physical texts, online research, and
                    using internal documents along with collecting data from what
                    AI outputs due to a researcher’s prompts.
                  </p>
                  <p>
                    AI-based provenance research documentation can be accomplished
                    a couple of ways; through noting specific AI findings through
                    interoffice memos, project notes, and citing the AI software
                    using the
                    <a href="https://www-chicagomanualofstyle-org.proxygw.wrlc.org/qanda/data/faq/topics/Documentation/faq0422.html" target="_blank">Chicago Manual of Style</a>.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">The Chicago Manual of Style Online.</span><span class="quire-citation__content" hidden="">The Chicago Manual of Style Online. “The Chicago Manual
                        of Style, 17th Edition.” Accessed November 14, 2023.
                        <a href="https://www.chicagomanualofstyle.org/" target="_blank">https://www.chicagomanualofstyle.org/</a>.</span></cite>) As part of the AI workflow, this transparency details areas
                    where human and AI data is used, benefiting the museum by
                    documenting the quality of the museum’s AI datasets and
                    modelling.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Dikow et al. 2023.</span><span class="quire-citation__content" hidden="">Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.</span></cite>)
                  </p>
                  <p>
                    There are organizations who provide frameworks of support
                    available in the navigation of ethical AI tools. The
                    <a href="https://airc.nist.gov/AI_RMF_Knowledge_Base" target="_blank">National Institute of Standards and Technology</a>
                    (NIST) suggests that subject matter experts should work within
                    AI “teams” to resolve issues regarding “alignment and
                    deployment conditions”(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">NIST AIRC</span><span class="quire-citation__content" hidden="">NIST AIRC. “NIST AIRC - AI RMF Core.” Accessed October
                        19, 2023.
                        <a href="https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF/Core_And_Profiles/5-sec-core" target="_blank">https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF/Core_And_Profiles/5-sec-core</a>.</span></cite>) and, if done correctly, will increase the “breadth and
                    diversity” of data and manages risks involving accuracy and
                    bias.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">NIST AIRC</span><span class="quire-citation__content" hidden="">NIST AIRC. “NIST AIRC - AI RMF Core.” Accessed October
                        19, 2023.
                        <a href="https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF/Core_And_Profiles/5-sec-core" target="_blank">https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF/Core_And_Profiles/5-sec-core</a>.</span></cite>)
                  </p>
                  <h3><em>Accuracy</em></h3>
                  <p>
                    Given the complexity of human language, user error, data
                    sourcing by the software and the developer’s algorithms, AI
                    has been known to respond incorrectly to a researcher’s
                    prompts. Based on my personal experiments with ChatGPT, Claude
                    2, and Google Bard, the responses have been thorough and clear
                    but, there have been some errors (the application recommended
                    imaginary sources) mixed within the response for each of these
                    MLL applications. Using the Department of the Interior’s,
                    Native American Graves Protection and Repatriation Act and the
                    United Nations Declaration of Indigenous People texts, I
                    prompted the various AI applications to answer questions
                    regarding museum repatriation based on the text. My
                    experiments provided insight into the need for proper staff
                    training when using these applications - I have never used AI
                    prior to writing this paper so the initial interaction was
                    interesting. Because I am familar with both documents, I was
                    able to determine the accuracy of the AI responses to my
                    experimental prompts.
                  </p>
                  <p>
                    <strong>Hallucinations</strong> or confabulations of
                    information occur either due to insufficient training data or
                    lack of appropriate source data to provide a correct response.
                    (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Matsakis 2023</span><span class="quire-citation__content" hidden="">Matsakis, Louise. “Artificial Intelligence May Not
                        ‘Hallucinate’ After All.” Wired. Accessed November 6,
                        2023.
                        <a href="https://www.wired.com/story/adversarial-examples-ai-may-not-hallucinate/" target="_blank">https://www.wired.com/story/adversarial-examples-ai-may-not-hallucinate/</a>.</span></cite>) There are circumstances where AI software could answer the
                    same prompt differently and incorrectly in the same
                    session.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Weise and Metz 2023</span><span class="quire-citation__content" hidden="">Weise, Karen, and Cade Metz. “When A.I. Chatbots
                        Hallucinate.” The New York Times, May 1, 2023, sec.
                        Business.
                        <a href="https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html" target="_blank">https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html</a>.</span></cite>) The information the AI generated is false or fabricated and
                    this may occur due to a couple of factors. One way these
                    fabrications enter into responses is from untruthful
                    information already on the web and AI reiterates what it sees
                    as truth; often occurring when AI uses the web to answer a
                    prompt. Another reason for inaccuracy is the predictive nature
                    of the software as the algorithm detects and produces patterns
                    in various ways. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Weise and Metz 2023</span><span class="quire-citation__content" hidden="">Weise, Karen, and Cade Metz. “When A.I. Chatbots
                        Hallucinate.” The New York Times, May 1, 2023, sec.
                        Business.
                        <a href="https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html" target="_blank">https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html</a>.</span></cite>) Weise and Metz state that some AI companies have been
                    working to resolve accuracy issues with “feedback from human
                    testers” also called <strong>reinforcement learning</strong>.
                    (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Weise and Metz 2023</span><span class="quire-citation__content" hidden="">Weise, Karen, and Cade Metz. “When A.I. Chatbots
                        Hallucinate.” The New York Times, May 1, 2023, sec.
                        Business.
                        <a href="https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html" target="_blank">https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html</a>.</span></cite>) As provenance research uses many sources of information to
                    prove or disprove gaps in ownership, hallucinations, for the
                    time being, will require additional steps to fact-check and
                    note and using designated datasets and models created for
                    specific research purposes creating a closed system approach
                    that avoids outside biased data. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">OpenAI 2023</span><span class="quire-citation__content" hidden="">OpenAI. “GPT-4 System Card,” March 23, 2023.</span></cite>)
                  </p>
                  <h2>Some Considerations</h2>
                  <h3><em>Education</em></h3>
                  <p>
                    With education and training in AI, abundant on the web,
                    museums should consider standardized training in use, as far
                    as provenance research is concerned so staff are prepared to
                    properly use the software to get the best result. Github and
                    OpenAI have resources to prepare museum staff but it would be
                    best to come to an agreement on what resources and authorities
                    should be involved in the process of training. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Build Software Better, Together</span><span class="quire-citation__content" hidden="">“Build Software Better, Together.” n.d. GitHub. Accessed
                        December 2, 2023.
                        <a href="https://github.com" target="_blank">https://github.com</a>.</span></cite>)(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">OpenAI Platform</span><span class="quire-citation__content" hidden="">OpenAI Platform.” n.d. Accessed December 2, 2023.
                        <a href="https://platform.openai.com" target="_blank">https://platform.openai.com</a>.</span></cite>) Provenance researchers who do not use properly trained AI
                    applications (or choose incorrect datasets) risk inaccurate
                    and biased results if they are not properly trained.
                  </p>
                  <h3><em>AI Workflows</em></h3>
                  <p>
                    Museums suffer from a lack of “TMPR”, or time, money, people,
                    and resources.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Weisberg 2023</span><span class="quire-citation__content" hidden="">Weisberg, Robert J. “Is AI the Right or Wrong Solution to
                        the Right or Wrong Problem?” Museum Human, October 24,
                        2023.
                        <a href="https://www.museumhuman.com/is-ai-the-right-or-wrong-solution-to-the-right-or-wrong-problem/" target="_blank">https://www.museumhuman.com/is-ai-the-right-or-wrong-solution-to-the-right-or-wrong-problem/</a>.</span></cite>) AI project cycles map out benchmarks that maximize the
                    benfits of AI to get more return on investment.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Maddula 2021</span><span class="quire-citation__content" hidden="">Maddula, Surya. “The AI Project Cycle.” Medium (blog),
                        November 4, 2021.
                        <a href="https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f" target="_blank">https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f</a>.</span></cite>)
                  </p>
                  <p>
                    For the purpose of project efficiency, an AI project cycle
                    should include:
                  </p>
                  <ul>
                    <li>Problem Idenitified.</li>
                    <li>Project scope.</li>
                    <li>
                      Data acquisition.<sup class="footnote-ref"><a href="#fn7" id="fnref7" class="footnote-ref-anchor">7</a></sup>
                    </li>
                    <li>
                      Data exploration where patterns in information are explored
                      using the 4 W’s.<sup class="footnote-ref"><a href="#fn8" id="fnref8" class="footnote-ref-anchor">8</a></sup>
                    </li>
                    <li>
                      AI Modelling is fed into the AI.<sup class="footnote-ref"><a href="#fn9" id="fnref9" class="footnote-ref-anchor">9</a></sup>
                    </li>
                    <li>Evaluation of AI.</li>
                    <li>
                      Deployment of AI or integration.<br />
                      (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Maddula 2021</span><span class="quire-citation__content" hidden="">Maddula, Surya. “The AI Project Cycle.” Medium (blog),
                          November 4, 2021.
                          <a href="https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f" target="_blank">https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f</a>.</span></cite>)
                    </li>
                  </ul>
                  <p>
                    Once deployment is underway, having an established provenance
                    research workflow is important to project derailment,
                    establish focus, manage museum resources. Museums should
                    consider how their provenance research workflow will involve
                    AI and what data sources will be permitted for use. The
                    Smithsonian Institution supports documenting “how the AI
                    content was produced” and delineating between “human” and “AI”
                    generated content. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">AI Values Statement 2022</span><span class="quire-citation__content" hidden="">“AI Values Statement.” AI Values Statement | Smithsonian
                        Data Science Lab, 2022.
                        <a href="https://datascience.si.edu/ai-values-statement" target="_blank">https://datascience.si.edu/ai-values-statement</a>.</span></cite>)
                  </p>
                  <p>
                    The project scope determines what information is lacking
                    within the object file and, using the AI project cycle,
                    determines a means to expedite the process and deploys the
                    model for use within the provenance research workflow.
                    Workflows in museums should include a documented plan that
                    includes: strategy, project cycle, materials and AI
                    applications used and a final reporting. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Dikow et al. 2023.</span><span class="quire-citation__content" hidden="">Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.</span></cite>) Part of the Smithsonian Institution’s
                    <em>AI Values Statement</em> requires staff to consider if AI
                    is appropriate for solving the problem (project scope). (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Dikow et al. 2023.</span><span class="quire-citation__content" hidden="">Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.</span></cite>) Provenance research workflows should include what the final
                    deliverables will include and how due diligence is proven.
                    Once provenance decisions are finalized and additions are made
                    to an object’s file, AI usage should be publicly indicated
                    within the provenance record. According to the Carnegie Museum
                    of Art provenance standard, a footnote or a note at the end of
                    the provenance record could be used to note AI-use. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Art Tracks</span><span class="quire-citation__content" hidden="">“Art Tracks | Art Tracks.” Accessed September 6, 2023.
                        <a href="http://www.museumprovenance.org/" target="_blank">http://www.museumprovenance.org/</a>.</span></cite>) Until a standardization for AI is created, these additions
                    can provide transparency of use for museums.
                  </p>
                  <h3><em>Matters of Privacy</em></h3>
                  <p>
                    Museum staff must consider how to handle matters regarding
                    personal and museum data when conducting AI-based provenance
                    research. While using AI applications, such as ChatGPT, data
                    is collected from its users such as interaction data, browser
                    settings, and internet protocol, or IP addresses,
                    “conversation titles,” and “chat histories” which are made
                    available to third parties during use. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Khowaja et al. 2023, 6-7</span><span class="quire-citation__content" hidden="">Khowaja, Sunder Ali, Parus Khuwaja, and Kapal Dev.
                        “ChatGPT Needs SPADE (Sustainability, Privacy, Digital
                        Divide, and Ethics) Evaluation: A Review.” arXiv, April
                        13, 2023.
                        <a href="http://arxiv.org/abs/2305.03123" target="_blank">http://arxiv.org/abs/2305.03123</a>.</span></cite>) This means internal documents that hold donor data, museum
                    operational information and others could be made public on the
                    web. Museum management should carefully review the
                    application’s privacy policy during the vetting process to
                    ensure they align with the museum’s ethical standards and
                    practices.
                  </p>
                  <p>
                    There are ways to protect AI usage that include
                    <em>tokenization</em> or replacing sensitive data with
                    non-sensitive tokens making data unavailable to unauthorized
                    users, and (similar to tokenization) <em>data masking</em>, or
                    the scrambling of data while maintaining its basic structure.
                    (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Takyar 2023</span><span class="quire-citation__content" hidden="">Takyar, Akash. “Data Security in AI Systems.” LeewayHertz
                        - AI Development Company, June 19, 2023.
                        <a href="https://www.leewayhertz.com/data-security-in-ai-systems/" target="_blank">https://www.leewayhertz.com/data-security-in-ai-systems/</a>.</span></cite>) These options may require additional research to integrate
                    into current AI project cycles.
                  </p>
                  <p>
                    Within the museum environment, provenance researchers can
                    mitigate privacy concerns by:
                  </p>
                  <ul>
                    <li>
                      Using models solely trained on local devices locally within
                      the institution’s protected servers.
                    </li>
                    <li>
                      Instituting security measures that protect personal and
                      museum data during use.
                    </li>
                    <li>
                      Creating and enforcing ethical data usage policies that
                      include using biased data, user data, and data sharing.
                    </li>
                    <li>
                      Training researchers of the implications of non-adherence to
                      museum data privacy policies.<br />
                      (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Khowaja et al. 2023, 7</span><span class="quire-citation__content" hidden="">Khowaja, Sunder Ali, Parus Khuwaja, and Kapal Dev.
                          “ChatGPT Needs SPADE (Sustainability, Privacy, Digital
                          Divide, and Ethics) Evaluation: A Review.” arXiv, April
                          13, 2023.
                          <a href="http://arxiv.org/abs/2305.03123" target="_blank">http://arxiv.org/abs/2305.03123</a>.</span></cite>)
                    </li>
                  </ul>
                  <h3><em>Indigenous Cultures</em></h3>
                  <p>
                    Another provenance research use of AI is in the determination
                    for object repatriation for indigenous cultures for the
                    purposes of NAGPRA. Using AI for provenance determinations of
                    indigenous cultural property is not appropriate without a
                    conversation with the affected cultural group. (<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Lewis et al. 2020.</span><span class="quire-citation__content" hidden="">Lewis, Jason Edward, Angie Abdilla, Noelani Arista,
                        Kaipulaumakaniolono Baker, Scott Benesiinaabandan,
                        Michelle Brown, Melanie Cheung, et al. “Indigenous
                        Protocol and Artificial Intelligence Position Paper.”
                        Monograph. Honolulu, HI: Indigenous Protocol and
                        Artificial Intelligence Working Group and the Canadian
                        Institute for Advanced Research, 2020.
                        <a href="https://doi.org/10.11573/spectrum.library.concordia.ca.00986506" target="_blank">https://doi.org/10.11573/spectrum.library.concordia.ca.00986506</a>.</span></cite>) A
                    <a href="https://www.indigenous-ai.net/position-paper/" target="_blank">position paper</a>, written by
                    <a href="https://www.indigenous-ai.net/" target="_blank">The Indigenous Protocol and Artificial Intelligence Working
                      Group</a>, has been created for those interested in learning more
                    about different cultural positions regarding AI use. Using AI
                    in cases for determining and researching Indigenous cultures
                    should also be addressed in the museum’s ethical stewardship
                    policies within its collection management plan.
                  </p>
                  <h2>Conclusion</h2>
                  <p>
                    Museums stand to benefit significantly as backlogs of
                    ownership investigations are resolved from AI-based provenance
                    research; collections become more available for exhibition,
                    study, and programming. AI-based provenance research could
                    positively impact collection object access by providing
                    provenance researchers a means of processing large amounts of
                    information in a shorter timeframes.
                  </p>
                  <p>
                    As mentioned, AI technology contains risks that can negatively
                    affect a museum’s authority over its collection. Understanding
                    the AI project cycle is essential to identifying how the
                    different bias types are introduced can help provenance
                    researchers to avoid them. By proactively mitigating bias,
                    museums can confidently and openly use AI for provenance
                    research. Education and focused training in data creation and
                    LLM usage can help subvert most inaccurate AI outputs.
                    Transparently documenting AI use, auditing for biases,
                    controlling data inputs, and adhering to emerging best
                    practices around ethical AI development, improve AI models for
                    continued use for both the provenance researcher and the
                    museum.
                  </p>
                  <p>
                    AI technology is rapidly evolving; museums can establish
                    responsible use by clearly defining project scopes, workflows,
                    and intended applications. AI is an incredibly intense and
                    intimidating application that could potentially hinder
                    productivity and result in faulty responses if not used
                    properly. Learning about the elements of AI in a group ensures
                    staff is on the same page for developing policies, training,
                    and ethical standards. Key terminology has been defined to
                    provide a means of navigating and encouraging discussions
                    regarding AI integration into a provenance workflow. The
                    ultimate goal for AI-based provenance research is developing a
                    technological tool that supports provenance researchers in
                    acquiring the information needed to make underdocumented
                    objects valued as educational tools for the public.
                  </p>
                  <h2>Notes</h2>
                  <section class="footnotes">
                    <ol class="footnotes-list">
                      <li id="fn1" class="footnote-item">
                        <p>
                          ChatGPT, Claude 2, and Google Bard are examples of large
                          language models (LLMs).(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Coursera 2023</span><span class="quire-citation__content" hidden="">Coursera. “Artificial Intelligence (AI) Terms: A to
                              Z Glossary,” June 15, 2023.
                              <a href="https://www.coursera.org/articles/ai-terms" target="_blank">https://www.coursera.org/articles/ai-terms</a>.</span></cite>) <a href="#fnref1" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn2" class="footnote-item">
                        <p>
                          This definition makes sense when considering early
                          computing where binary language, a language of ones and
                          zeros, was the “early” linear vector for simple computer
                          operations. Word vectors indicate general human word
                          relationships represented as contextual numerical
                          coordinates.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Lee and Trott 2023</span><span class="quire-citation__content" hidden="">Lee, Timothy B., and Sean Trott. “A Jargon-Free
                              Explanation of How AI Large Language Models Work.”
                              Ars Technica, July 31, 2023.
                              <a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" target="_blank">https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/</a>.</span></cite>) <a href="#fnref2" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn3" class="footnote-item">
                        <p>
                          The <em>predictive</em> function, based on patterns may
                          occur, is already popular; seen in some computer
                          applications, for example, anticipating text selections
                          in emails and Netflix user recommendations. The
                          <em>presciptive</em> function uses data to predict what
                          will happen based on past patttern in data.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Wikipedia</span><span class="quire-citation__content" hidden="">Wikipedia. “Artificial Intelligence.” Reference,
                              October 18, 2023.
                              <a href="https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&amp;oldid=1180679786#Applications" target="_blank">https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&amp;oldid=1180679786#Applications</a>.</span></cite>) <a href="#fnref3" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn4" class="footnote-item">
                        <p>
                          Within machine learning are four approaches to learning
                          algorithms: supervised or directly trained by a user,
                          semi-supervised where there is a mix of both labeled and
                          unlabeled data where the model must find patterns to
                          structure the data, unsupervised where the algorithm
                          detects patterns on its own, and reinforcement where
                          algorithm learns when success is achieved.(<cite class="quire-citation expandable"><span class="quire-citation__button" role="button" tabindex="0" aria-expanded="false">Gavrilova 2020</span><span class="quire-citation__content" hidden="">Gavrilova, Yulia. “AI vs. ML vs. DL: What’s the
                              Difference.” Blog. Serokell Software Development
                              Company, April 8, 2020.
                              <a href="https://serokell.io/blog/ai-ml-dl-difference" target="_blank">https://serokell.io/blog/ai-ml-dl-difference</a>.</span></cite>) <a href="#fnref4" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn5" class="footnote-item">
                        <p>
                          Based on my experiences during my internship and studies
                          at George Washington University Museum Studies Graduate
                          program.
                          <a href="#fnref5" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn6" class="footnote-item">
                        <p>
                          The Python.org website features instruction and
                          informational pages for AI.
                          <a href="#fnref6" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn7" class="footnote-item">
                        <p>
                          As mentioned earlier in the paper, AI can transcribe
                          written texts and used for AI modeling.
                          <a href="#fnref7" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn8" class="footnote-item">
                        <p>
                          The 4 W’s: The Who, What, Where, and Why.
                          <a href="#fnref8" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                      <li id="fn9" class="footnote-item">
                        <p>
                          There is the learning based approach where the AI is
                          trained using one of three learning methods: supervised,
                          semi-supervised, unsupervised, and reinforcement. To
                          learn more, read, “Click
                          <a href="https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f" target="_blank">AI Project Lifecycle</a>,” <a href="#fnref9" class="footnote-backref">↩︎</a>
                        </p>
                      </li>
                    </ol>
                  </section>

                  <div class="quire-page__content__references backmatter">
                    <h2>Bibliography</h2>
                    <ul>
                      <li id="agrawal-gans-and-goldfarb-2019">
                        Agrawal, Ajay, Joshua S. Gans, and Avi Goldfarb.
                        “Artificial Intelligence: The Ambiguous Labor Market
                        Impact of Automating Prediction.”
                        <em>Journal of Economic Perspectives</em> 33, no. 2 (May
                        1, 2019): 31-50.
                        <a href="https://doi.org/10.1257/jep.33.2.31" target="_blank">https://doi.org/10.1257/jep.33.2.31</a>.
                      </li>

                      <li id="ai-values-statement-2022">
                        “AI Values Statement.” AI Values Statement | Smithsonian
                        Data Science Lab, 2022.
                        <a href="https://datascience.si.edu/ai-values-statement" target="_blank">https://datascience.si.edu/ai-values-statement</a>.
                      </li>

                      <li id="angwin-et-al-2023">
                        Angwin, Julia, Jeff Larson, Lauren Kirchner, and Surya
                        Mattu. “Machine Bias.” ProPublica. Accessed November 14,
                        2023.
                        <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a>.
                      </li>

                      <li id="art-tracks">
                        “Art Tracks | Art Tracks.” Accessed September 6, 2023.
                        <a href="http://www.museumprovenance.org/" target="_blank">http://www.museumprovenance.org/</a>.
                      </li>

                      <li id="biddle-2022">
                        Biddle, Sam. “The Internet’s New Favorite AI Proposes
                        Torturing Iranians and Surveilling Mosques.” The
                        Intercept, December 8, 2022.
                        <a href="https://theintercept.com/2022/12/08/openai-chatgpt-ai-bias-ethics/" target="_blank">https://theintercept.com/2022/12/08/openai-chatgpt-ai-bias-ethics/</a>.
                      </li>

                      <li id="brannon-su-vergara-and-villasenor-2022">
                        Brannon, Isabella, Allen Su, Caitlyn Vergara, and John
                        Villasenor. “AI &amp; Bias - When Algorithms Don’t Work,”
                        YouTube video. 7:13. September 14, 2022.
                        <a href="https://www.youtube.com/watch?v=FD-4yC95iZY" target="_blank">https://www.youtube.com/watch?v=FD-4yC95iZY</a>.
                      </li>

                      <li id="brown-2021">
                        Brown, Sara. “Machine Learning, Explained | MIT Sloan.”
                        Education. MIT Management Sloan School, April 21, 2021.
                        <a href="https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained" target="_blank">https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained</a>.
                      </li>

                      <li id="build-software-better-together">
                        “Build Software Better, Together.” n.d. GitHub. Accessed
                        December 2, 2023.
                        <a href="https://github.com" target="_blank">https://github.com</a>.
                      </li>

                      <li id="christou-2023">
                        Christou, Prokopis. “How to Use Artificial Intelligence
                        (AI) as a Resource, Methodological and Analysis Tool in
                        Qualitative Research?” The Qualitative Report, July 31,
                        2023.
                        <a href="https://doi.org/10.46743/2160-3715/2023.6406" target="_blank">https://doi.org/10.46743/2160-3715/2023.6406</a>.
                      </li>

                      <li id="collecting-and-provenance-research">
                        “Collecting &amp; Provenance Research (Getty Research
                        Institute).” Accessed November 30, 2023.
                        <a href="https://www.getty.edu/research/tools/provenance/" target="_blank">https://www.getty.edu/research/tools/provenance/</a>.
                      </li>

                      <li id="coursera-2023">
                        Coursera. “Artificial Intelligence (AI) Terms: A to Z
                        Glossary,” June 15, 2023.
                        <a href="https://www.coursera.org/articles/ai-terms" target="_blank">https://www.coursera.org/articles/ai-terms</a>.
                      </li>

                      <li id="dikow-et-al-2023">
                        Dikow, Rebecca B, Corey DiPietro, Michael G Trizna, Hanna
                        BredenbeckCorp, Madeline G Bursell, Jenna T B Ekwealor,
                        Richard G J Hodel, et al. “Developing Responsible AI
                        Practices at the Smithsonian Institution.” Research Ideas
                        and Outcomes 9 (October 25, 2023): e113334.
                        <a href="https://doi.org/10.3897/rio.9.e113334" target="_blank">https://doi.org/10.3897/rio.9.e113334</a>.
                      </li>

                      <li id="gavrilova-2020">
                        Gavrilova, Yulia. “AI vs. ML vs. DL: What’s the
                        Difference.” Blog. Serokell Software Development Company,
                        April 8, 2020.
                        <a href="https://serokell.io/blog/ai-ml-dl-difference" target="_blank">https://serokell.io/blog/ai-ml-dl-difference</a>.
                      </li>

                      <li id="khowaja-et-al-2023">
                        Khowaja, Sunder Ali, Parus Khuwaja, and Kapal Dev.
                        “ChatGPT Needs SPADE (Sustainability, Privacy, Digital
                        Divide, and Ethics) Evaluation: A Review.” arXiv, April
                        13, 2023.
                        <a href="http://arxiv.org/abs/2305.03123" target="_blank">http://arxiv.org/abs/2305.03123</a>.
                      </li>

                      <li id="lee-and-trott-2023">
                        Lee, Timothy B., and Sean Trott. “A Jargon-Free
                        Explanation of How AI Large Language Models Work.” Ars
                        Technica, July 31, 2023.
                        <a href="https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/" target="_blank">https://arstechnica.com/science/2023/07/a-jargon-free-explanation-of-how-ai-large-language-models-work/</a>.
                      </li>

                      <li id="lewis-et-al-2020">
                        Lewis, Jason Edward, Angie Abdilla, Noelani Arista,
                        Kaipulaumakaniolono Baker, Scott Benesiinaabandan,
                        Michelle Brown, Melanie Cheung, et al. “Indigenous
                        Protocol and Artificial Intelligence Position Paper.”
                        Monograph. Honolulu, HI: Indigenous Protocol and
                        Artificial Intelligence Working Group and the Canadian
                        Institute for Advanced Research, 2020.
                        <a href="https://doi.org/10.11573/spectrum.library.concordia.ca.00986506" target="_blank">https://doi.org/10.11573/spectrum.library.concordia.ca.00986506</a>.
                      </li>

                      <li id="murphy-2022">
                        Loughborough University IAS. “Dr Oonagh Murphy - AI
                        Technologies and Emerging Museum Practices.” YouTube
                        video. 30:11. March 31, 2022.
                        <a href="https://www.youtube.com/watch?v=16QxXBFo4Ps" target="_blank">https://www.youtube.com/watch?v=16QxXBFo4Ps</a>.
                      </li>

                      <li id="maddula-2021">
                        Maddula, Surya. “The AI Project Cycle.” Medium (blog),
                        November 4, 2021.
                        <a href="https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f" target="_blank">https://suryamaddula.medium.com/the-ai-project-cycle-e363ce3f4f6f</a>.
                      </li>

                      <li id="malaro-and-deangelis-2012">
                        Malaro, Marie C., and Ildiko Pogany DeAngelis.
                        <em>A Legal Primer on Managing Museum Collections.</em>
                        Third. Washington: Smithsonian Books, 2012. Kindle.
                      </li>

                      <li id="matsakis-2023">
                        Matsakis, Louise. “Artificial Intelligence May Not
                        ‘Hallucinate’ After All.” Wired. Accessed November 6,
                        2023.
                        <a href="https://www.wired.com/story/adversarial-examples-ai-may-not-hallucinate/" target="_blank">https://www.wired.com/story/adversarial-examples-ai-may-not-hallucinate/</a>.
                      </li>

                      <li id="murphy-and-villaespesa-2020">
                        Murphy, Oonagh, and Elena Villaespesa.
                        <em>The Museums + AI Network AI: A Museum Planning
                          Toolkit.</em>
                        Goldsmiths, January 2020.
                      </li>

                      <li id="nist-airc">
                        NIST AIRC. “NIST AIRC - AI RMF Core.” Accessed October 19,
                        2023.
                        <a href="https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF/Core_And_Profiles/5-sec-core" target="_blank">https://airc.nist.gov/AI_RMF_Knowledge_Base/AI_RMF/Core_And_Profiles/5-sec-core</a>.
                      </li>

                      <li id="openai-2023">
                        OpenAI. “GPT-4 System Card,” March 23, 2023.
                      </li>

                      <li id="openai-platform">
                        OpenAI Platform.” n.d. Accessed December 2, 2023.
                        <a href="https://platform.openai.com" target="_blank">https://platform.openai.com</a>.
                      </li>

                      <li id="pasick-2023">
                        Pasick, Adam. “Artificial Intelligence Glossary: Neural
                        Networks and Other Terms Explained.” The New York Times,
                        March 27, 2023, sec. Technology.
                        <a href="https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html" target="_blank">https://www.nytimes.com/article/ai-artificial-intelligence-glossary.html</a>.
                      </li>

                      <li id="reagan-2021">
                        Reagan, Mary. “Understanding Bias and Fairness in AI
                        Systems.” Medium, April 2, 2021.
                        <a href="https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3" target="_blank">https://towardsdatascience.com/understanding-bias-and-fairness-in-ai-systems-6f7fbfe267f3</a>.
                      </li>

                      <li id="stapleton-2023">
                        Stapleton, Andy. “How To Write An A+ Essay Using AI in 3
                        Simple Steps.” YouTube video. 8:08. October 30, 2023.
                        <a href="https://www.youtube.com/watch?v=EeMm-kaYgI0" target="_blank">https://www.youtube.com/watch?v=EeMm-kaYgI0</a>.
                      </li>

                      <li id="takyar-2023">
                        Takyar, Akash. “Data Security in AI Systems.” LeewayHertz
                        - AI Development Company, June 19, 2023.
                        <a href="https://www.leewayhertz.com/data-security-in-ai-systems/" target="_blank">https://www.leewayhertz.com/data-security-in-ai-systems/</a>.
                      </li>

                      <li id="tds-editors-2021">
                        TDS Editors. “Why Eliminating Bias in AI Systems Is So
                        Hard.” Medium, October 28, 2021.
                        <a href="https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93" target="_blank">https://towardsdatascience.com/why-eliminating-bias-in-ai-systems-is-so-hard-97e4f60ffe93</a>.
                      </li>

                      <li id="the-chicago-manual-of-style-online">
                        The Chicago Manual of Style Online. “The Chicago Manual of
                        Style, 17th Edition.” Accessed November 14, 2023.
                        <a href="https://www.chicagomanualofstyle.org/" target="_blank">https://www.chicagomanualofstyle.org/</a>.
                      </li>

                      <li id="its-group">
                        “The Evolution of Document Scanning - How Can AI Help You?
                        | ITS Group.” Accessed November 25, 2023.
                        <a href="https://www.its-group.com/news/story/the-evolution-of-document-scanning-how-can-i-help-you" target="_blank">https://www.its-group.com/news/story/the-evolution-of-document-scanning-how-can-i-help-you</a>.
                      </li>

                      <li id="the-history-of-artificial-intelligence-2022">
                        “The History of Artificial Intelligence (4K) | CyberWork
                        And The American Dreams | Spark.” YouTube video. 55:37.
                        July 13, 2022.
                        <a href="https://www.youtube.com/watch?v=q6U9mhKAFFA" target="_blank">https://www.youtube.com/watch?v=q6U9mhKAFFA</a>.
                      </li>

                      <li id="villaespesa-and-french-2019">
                        Villaespesa, Elena, and Ariana French. “AI, Visitor
                        Experience, and Museum Operations: A Closer Look at the
                        Possible.” 101-13, 2019.
                      </li>

                      <li id="weisberg-2023">
                        Weisberg, Robert J. “Is AI the Right or Wrong Solution to
                        the Right or Wrong Problem?” Museum Human, October 24,
                        2023.
                        <a href="https://www.museumhuman.com/is-ai-the-right-or-wrong-solution-to-the-right-or-wrong-problem/" target="_blank">https://www.museumhuman.com/is-ai-the-right-or-wrong-solution-to-the-right-or-wrong-problem/</a>.
                      </li>

                      <li id="weise-and-metz-2023">
                        Weise, Karen, and Cade Metz. “When A.I. Chatbots
                        Hallucinate.” The New York Times, May 1, 2023, sec.
                        Business.
                        <a href="https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html" target="_blank">https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucination.html</a>.
                      </li>

                      <li id="wikipedia">
                        Wikipedia. “Artificial Intelligence.” Reference, October
                        18, 2023.
                        <a href="https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&amp;oldid=1180679786#Applications" target="_blank">https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&amp;oldid=1180679786#Applications</a>.
                      </li>
                    </ul>
                  </div>
                </div>

              </div>
            </section>
          </body>
</html>
